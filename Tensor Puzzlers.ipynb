{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d38fbd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81be229b",
   "metadata": {},
   "source": [
    "# Tensor Puzzles\n",
    "- [Sasha Rush](http://rush-nlp.com)\n",
    "\n",
    "\n",
    "When starting with a tensor programming language like PyTorch or\n",
    "Numpy it is tempting to rely on the standard library (or more\n",
    "honestly stackoverflow) to find a function for everything.\n",
    "But in practice, the tensor language is extremely expressive.\n",
    "You can do most things from first principles.\n",
    "\n",
    "\n",
    "This is a collection of 15 tensor puzzles. Like chess puzzles these are\n",
    "not meant to simulate the complexity of a real program, but to practice\n",
    "in a simplified environment. Each puzzle asks you to reimplement one\n",
    "function in the NumPy standard.\n",
    "\n",
    "### Rules\n",
    "\n",
    "1) Each can be solved in 1 line (<80 columns) of code.\n",
    "2) You are allowed  @, *, ==, <=, indexing, and previous puzzle functions.\n",
    "3) Additionally you are allowed these two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297931e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def arange(i: int):\n",
    "    \"Think for-loop\"\n",
    "    return torch.tensor(range(i))\n",
    "\n",
    "\n",
    "def where(q, a, b):\n",
    "    \"Think if-statement\"\n",
    "    return (q * a) + (~q) * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1d789",
   "metadata": {},
   "source": [
    "\n",
    "### Anti-Rules\n",
    "\n",
    "1) Nothing else. No `view`, `sum`, `take`, `squeeze`, `tensor`.\n",
    "2) No cheating. Stackoverflow is great, but this is about first-principles.\n",
    "\n",
    "\n",
    "### Running puzzles\n",
    "\n",
    "Each example, corresponds to a unit test which will randomly\n",
    "try to break your code based on the spec.\n",
    "\n",
    "To run these you can run with `pytest`. If you are runing in a\n",
    "notebook, just uncomment the test for each example.\n",
    "\n",
    "[Start at problem 1!](#puzzle-1---ones).\n",
    "\n",
    "\n",
    "## Test Harness\n",
    "\n",
    "Here is the code for automatic testing (if you are interested), or you can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtyping hypothesis pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dce1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import typing\n",
    "from hypothesis.extra.numpy import arrays\n",
    "from hypothesis.strategies import integers, tuples, composite, floats\n",
    "from hypothesis import given\n",
    "import numpy as np\n",
    "from torchtyping import TensorType\n",
    "\n",
    "\n",
    "size = integers(min_value=1, max_value=5)\n",
    "\n",
    "tensor = torch.tensor\n",
    "\n",
    "numpy_to_torch_dtype_dict = {\n",
    "    bool: torch.bool,\n",
    "    np.uint8: torch.uint8,\n",
    "    np.int8: torch.int8,\n",
    "    np.int16: torch.int16,\n",
    "    np.int32: torch.int32,\n",
    "    np.int64: torch.int64,\n",
    "    np.float16: torch.float16,\n",
    "    np.float32: torch.float32,\n",
    "    np.float64: torch.float64,\n",
    "}\n",
    "torch_to_numpy_dtype_dict = {v: k for k, v in numpy_to_torch_dtype_dict.items()}\n",
    "\n",
    "\n",
    "@composite\n",
    "def spec(draw, x):\n",
    "\n",
    "    names = set()\n",
    "    gth = typing.get_type_hints(x)\n",
    "    for k in gth:\n",
    "        if not hasattr(gth[k], \"__metadata__\"):\n",
    "            continue\n",
    "        dims = gth[k].__metadata__[0][\"details\"][0].dims\n",
    "        names.update([d.name for d in dims if isinstance(d.name, str)])\n",
    "    names = list(names)\n",
    "    arr = draw(tuples(*[size for _ in range(len(names))]))\n",
    "    sizes = dict(zip(names, arr))\n",
    "    ret = {}\n",
    "\n",
    "    for k in gth:\n",
    "        if not hasattr(gth[k], \"__metadata__\"):\n",
    "            continue\n",
    "        shape = tuple(\n",
    "            [\n",
    "                sizes[d.name] if isinstance(d.name, str) else d.size\n",
    "                for d in gth[k].__metadata__[0][\"details\"][0].dims\n",
    "            ]\n",
    "        )\n",
    "        ret[k] = draw(\n",
    "            arrays(\n",
    "                shape=shape,\n",
    "                dtype=torch_to_numpy_dtype_dict[\n",
    "                    gth[k].__metadata__[0][\"details\"][1].dtype\n",
    "                ]\n",
    "                if len(gth[k].__metadata__[0][\"details\"]) >= 2\n",
    "                else int,\n",
    "            )\n",
    "        )\n",
    "        ret[k][ret[k] > 1000] = 1000\n",
    "        ret[k][ret[k] < -1000] = -1000\n",
    "        ret[k] = np.nan_to_num(ret[k], nan=0, neginf=0, posinf=0)\n",
    "\n",
    "    ret[\"return\"][:] = 0\n",
    "    return ret, sizes\n",
    "\n",
    "\n",
    "def make_test(problem, problem_spec, add_sizes=[], constraint=lambda d: d):\n",
    "    @given(spec(problem))\n",
    "    def test_problem(d):\n",
    "        d, sizes = d\n",
    "        d = constraint(d)\n",
    "        out = d[\"return\"].tolist()\n",
    "        del d[\"return\"]\n",
    "        problem_spec(*d.values(), out)\n",
    "        for size in add_sizes:\n",
    "            d[size] = sizes[size]\n",
    "\n",
    "        out2 = problem(*map(tensor, d.values()))\n",
    "        out = tensor(out)\n",
    "        out2 = torch.broadcast_to(out2, out.shape)\n",
    "        assert torch.equal(\n",
    "            out, out2\n",
    "        ), \"Two tensors are not equal\\n Spec: \\n\\t%s \\n\\t%s\" % (out, out2)\n",
    "\n",
    "    return test_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d96ad7",
   "metadata": {},
   "source": [
    "## Puzzle 1 - ones\n",
    "\n",
    "Compute [ones](https://numpy.org/doc/stable/reference/generated/numpy.ones.html) - the vector of all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_spec(out):\n",
    "    for i in range(len(out)):\n",
    "        out[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd173832",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def ones(i: int) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_ones = make_test(ones, ones_spec, add_sizes=[\"i\"])\n",
    "# test_ones()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690b749",
   "metadata": {},
   "source": [
    "## Puzzle 2 - sum\n",
    "\n",
    "Compute [sum](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) - the sum of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_spec(a, out):\n",
    "    out[0] = 0\n",
    "    for i in range(len(a)):\n",
    "        out[0] += a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7204bf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def sum(a: TensorType[\"i\"]) -> TensorType[1]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_sum = make_test(sum, sum_spec)\n",
    "# test_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30320f05",
   "metadata": {},
   "source": [
    "## Puzzle 3 - outer\n",
    "\n",
    "Compute [outer](https://numpy.org/doc/stable/reference/generated/numpy.outer.html) - the outer product of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_spec(a, b, out):\n",
    "    for i in range(len(out)):\n",
    "        for j in range(len(out[0])):\n",
    "            out[i][j] = a[i] * b[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39684ae3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def outer(\n",
    "    a: TensorType[\n",
    "        \"i\",\n",
    "    ],\n",
    "    b: TensorType[\"j\"],\n",
    ") -> TensorType[\"i\", \"j\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_outer = make_test(outer, outer_spec)\n",
    "# test_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4733aa",
   "metadata": {},
   "source": [
    "## Puzzle 4 - diag\n",
    "\n",
    "Compute [diag](https://numpy.org/doc/stable/reference/generated/numpy.diag.html) - the diagonal vector of a square matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d14a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_spec(a, out):\n",
    "    for i in range(len(a)):\n",
    "        out[i] = a[i][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ced5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag(a: TensorType[\"i\", \"i\"]) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_diag = make_test(diag, diag_spec)()\n",
    "# test_diag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48753fcf",
   "metadata": {},
   "source": [
    "## Puzzle 5 - eye\n",
    "\n",
    "Compute [eye](https://numpy.org/doc/stable/reference/generated/numpy.eye.html) - the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_spec(out):\n",
    "    for i in range(len(out)):\n",
    "        out[i][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye(j: int) -> TensorType[\"j\", \"j\"]:\n",
    "    return where(arange(j)[:, None] == arange(j), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb95bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eye = make_test(eye, eye_spec, add_sizes=[\"j\"])\n",
    "# test_eye()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e76a0",
   "metadata": {},
   "source": [
    "## Puzzle 6 - triu\n",
    "\n",
    "Compute [triu](https://numpy.org/doc/stable/reference/generated/numpy.triu.html) - the upper triangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2274b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triu_spec(out):\n",
    "    for i in range(len(out)):\n",
    "        for j in range(len(out)):\n",
    "            if i <= j:\n",
    "                out[i][j] = 1\n",
    "            else:\n",
    "                out[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triu(j: int) -> TensorType[\"j\", \"j\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_triu = make_test(triu, triu_spec, add_sizes=[\"j\"])\n",
    "# test_triu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d1e96",
   "metadata": {},
   "source": [
    "## Puzzle 7 - cumsum\n",
    "\n",
    "Compute [cumsum](https://numpy.org/doc/stable/reference/generated/numpy.cumsum.html) - the cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_spec(a, out):\n",
    "    total = 0\n",
    "    for i in range(len(out)):\n",
    "        out[i] = total + a[i]\n",
    "        total += a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4664a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def cumsum(a: TensorType[\"i\"]) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_cumsum = make_test(cumsum, cumsum_spec)\n",
    "# test_cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04f27a",
   "metadata": {},
   "source": [
    "## Puzzle 8 - diff\n",
    "\n",
    "Compute [diff](https://numpy.org/doc/stable/reference/generated/numpy.diff.html) - the running difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_spec(a, out):\n",
    "    out[0] = a[0]\n",
    "    for i in range(1, len(out)):\n",
    "        out[i] = a[i] - a[i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(a: TensorType[\"i\"], i: int) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_diff = make_test(diff, diff_spec, add_sizes=[\"i\"])\n",
    "# test_diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb7a6c",
   "metadata": {},
   "source": [
    "## Puzzle 7 - vstack\n",
    "\n",
    "Compute [vstack](https://numpy.org/doc/stable/reference/generated/numpy.vstack.html) - the matrix of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f187b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstack_spec(a, b, out):\n",
    "    for i in range(len(out[0])):\n",
    "        out[0][i] = a[i]\n",
    "        out[1][i] = b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstack(a: TensorType[\"i\"], b: TensorType[\"i\"]) -> TensorType[2, \"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_vstack = make_test(vstack, vstack_spec)()\n",
    "# test_vstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715ea0f",
   "metadata": {},
   "source": [
    "## Puzzle 8 - roll\n",
    "\n",
    "Compute [roll](https://numpy.org/doc/stable/reference/generated/numpy.roll.html) - the vector shifted 1 circular position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_spec(a, out):\n",
    "    for i in range(len(out)):\n",
    "        if i + 1 < len(out):\n",
    "            out[i] = a[i + 1]\n",
    "        else:\n",
    "            out[i] = a[i + 1 - len(out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(a: TensorType[\"i\"], i: int) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_roll = make_test(roll, roll_spec, add_sizes=[\"i\"])\n",
    "# test_roll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a5554",
   "metadata": {},
   "source": [
    "## Puzzle 9 - flip\n",
    "\n",
    "Compute [flip](https://numpy.org/doc/stable/reference/generated/numpy.flip.html) - the reversed vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_spec(a, out):\n",
    "    for i in range(len(out)):\n",
    "        out[i] = a[len(out) - i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(a: TensorType[\"i\"], i: int) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_flip = make_test(flip, flip_spec, add_sizes=[\"i\"])\n",
    "# test_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc72cde",
   "metadata": {},
   "source": [
    "## Puzzle 10 - compress\n",
    "\n",
    "\n",
    "Compute [compress](https://numpy.org/doc/stable/reference/generated/numpy.flip.html) - keep only masked entries (left-aligned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5558b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_spec(groups, values, out):\n",
    "    j = 0\n",
    "    for i in range(len(groups)):\n",
    "        if groups[i]:\n",
    "            out[j] = values[i]\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a759fcf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def compress(groups: TensorType[\"i\", bool], values: TensorType[\"i\"]) -> TensorType[\"i\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "        groups[:, None], eye(groups.shape[0])[cumsum(groups.long()) - 1], 0\n",
    "    )\n",
    "\n",
    "\n",
    "test_compress = make_test(compress, compress_spec)\n",
    "# test_compress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e72cab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Puzzle 12 - pad_to\n",
    "\n",
    "\n",
    "Compute pad_to - eliminate or add 0s to change size of vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7239f62",
   "metadata": {
    "id": "-DsZHgOTroVN",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def pad_to_spec(a, out):\n",
    "    for i in range(min(len(out), len(a))):\n",
    "        out[i] = a[i]\n",
    "\n",
    "\n",
    "def pad_to(a: TensorType[\"i\"], i: int, j: int) -> TensorType[\"j\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "test_pad_to = make_test(pad_to, pad_to_spec, add_sizes=[\"i\", \"j\"])\n",
    "# test_pad_to()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e8f90",
   "metadata": {},
   "source": [
    "## Puzzle 13 - sequence_mask\n",
    "\n",
    "\n",
    "Compute [sequence_mask](https://www.tensorflow.org/api_docs/python/tf/sequence_mask) - pad out to length per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask_spec(values, length, out):\n",
    "    for i in range(len(out)):\n",
    "        for j in range(len(out[0])):\n",
    "            if j < length[i]:\n",
    "                out[i][j] = values[i][j]\n",
    "            else:\n",
    "                out[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad02673",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def sequence_mask(\n",
    "    values: TensorType[\"i\", \"j\"], length: TensorType[\"i\", int]\n",
    ") -> TensorType[\"i\", \"j\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "def constraint_set_length(d):\n",
    "    d[\"length\"] = d[\"length\"] % d[\"values\"].shape[0]\n",
    "    return d\n",
    "\n",
    "\n",
    "test_sequence = make_test(\n",
    "    sequence_mask, sequence_mask_spec, constraint=constraint_set_length\n",
    ")\n",
    "\n",
    "# test_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa8eb7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Puzzle 14: bincount\n",
    "\n",
    "Compute [bincount](https://numpy.org/doc/stable/reference/generated/numpy.bincount.html) - count number of times an entry was seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4610b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bincount_spec(a, out):\n",
    "    for i in range(len(a)):\n",
    "        out[a[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed885441",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def bincount(a: TensorType[\"i\"], j: int) -> TensorType[\"j\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "def constraint_set_max(d):\n",
    "    d[\"a\"] = d[\"a\"] % d[\"return\"].shape[0]\n",
    "    return d\n",
    "\n",
    "\n",
    "test_bincount = make_test(\n",
    "    bincount, bincount_spec, add_sizes=[\"j\"], constraint=constraint_set_max\n",
    ")\n",
    "# test_bincount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbf449",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Puzzle 15: scatter_add\n",
    "\n",
    "Compute `scatter_add` - add togeter values that scatter together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_add_spec(values, link, out):\n",
    "    for j in range(len(link)):\n",
    "        out[j] += values[link[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f62844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_add(\n",
    "    values: TensorType[\"i\"], link: TensorType[\"j\"], j: int\n",
    ") -> TensorType[\"j\"]:\n",
    "    # CHALLENGE\n",
    "    assert False, 'Not implemented yet.'\n",
    "\n",
    "\n",
    "def constraint_set_max(d):\n",
    "    d[\"link\"] = d[\"link\"] % d[\"values\"].shape[0]\n",
    "    return d\n",
    "\n",
    "\n",
    "test_scatter_add = make_test(\n",
    "    scatter_add, scatter_add_spec, add_sizes=[\"j\"], constraint=constraint_set_max\n",
    ")\n",
    "# test_scatter_add()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
